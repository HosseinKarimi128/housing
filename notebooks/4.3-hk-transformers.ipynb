{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-4070dd3e5464>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mOneHotEncoder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mload_data\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minternal_load\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mcolumnsSpliter\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mget_columns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmath\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.insert(0, 'C:/Users/h.karimi/Documents/pprojects/housing_hw/src/features')\n",
    "sys.path.insert(0, 'C:/Users/h.karimi/Documents/pprojects/housing_hw/src/data')\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from load_data import internal_load\n",
    "from columnsSpliter import get_columns\n",
    "import math\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zlib import crc32\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.insert(0, 'C:/Users/h.karimi/Documents/pprojects/housing_hw/src/features')\n",
    "sys.path.insert(0, 'C:/Users/h.karimi/Documents/pprojects/housing_hw/src/data')\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from load_data import internal_load\n",
    "from columnsSpliter import get_columns\n",
    "import math\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zlib import crc32\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data = internal_load(\"C:/Users/h.karimi/Documents/pprojects/housing_hw/data/interim/htt_with_lat_long.csv\")\n",
    "original_data = internal_load(\"C:/Users/h.karimi/Documents/pprojects/housing_hw/data/external/train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 10, \"display.max_columns\", None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class create_test_case(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, test_ratio, id_column):\n",
    "        self.test_ratio = test_ratio\n",
    "        self.id_column = id_column\n",
    "        return\n",
    "    def fit(self,data):\n",
    "        return self\n",
    "    def transform(self,data,y=None):\n",
    "        def test_set_check(identifier, test_ratio):\n",
    "            test_ratio = self.test_ratio\n",
    "            return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "        def split_train_test_by_id(data):\n",
    "            ids = data[self.id_column]\n",
    "            in_test_set = ids.apply(lambda id_: test_set_check(id_, self.test_ratio))\n",
    "            return data.loc[~in_test_set].reset_index(drop=True)\n",
    "        return split_train_test_by_id(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class address_to_latLong(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "    def fit(self,data):\n",
    "        return self\n",
    "    def transform(self,data,y=None):\n",
    "            switcher = {\"Blmngtn\":\"Bloomington Heights\",\"Blueste\":\"Bluestem\",\"BrDale\":\"Briardale\",\"BrkSide\":\"Brookside\",\"ClearCr\":\"Clear Creek\",\"CollgCr\":\"College Creek\",\"Crawfor\":\"Crawford\",\"Edwards\":\"Edwards\",\"Gilbert\":\"Gilbert\",\"IDOTRR\":\"Iowa DOT and Rail Road\",\"MeadowV\":\"Meadow Village\",\"Mitchel\":\"Mitchell\",\"Names\":\"North Ames\",\"NoRidge\":\"Northridge\",\"NPkVill\":\"Northpark Villa\",\"NridgHt\":\"Northridge Heights\",\"NWAmes\":\"Northwest Ames\",\"OldTown\":\"Old Town\",\"SWISU\":\"South & West of Iowa State University\",\"Sawyer\":\"Sawyer\",\"SawyerW\":\"Sawyer West\",\"Somerst\":\"Somerset\",\"StoneBr\":\"Stone Brook\",\"Timber\":\"Timberland\",\"Veenker\":\"Veenker\"}\n",
    "            def add_fullNeighborhood_columns(data,Neighborhood_attrib):\n",
    "                new_data = data.copy()\n",
    "            def Neighborhood_to_fullNeighborhood(argument):\n",
    "                new_data[\"fullNeighborhood\"] = new_data[Neighborhood_attrib].copy()\n",
    "                return switcher.get(argument, \"nothing\")\n",
    "                for item in new_data[Neighborhood_attrib].index:\n",
    "                    new_data[\"fullNeighborhood\"][item] = Neighborhood_to_fullNeighborhood(new_data[Neighborhood_attrib][item])\n",
    "                return new_data\n",
    "            def get_lat_long(data,address_attrib):\n",
    "                new_data = data.copy()\n",
    "                neighborhood_dict = switcher.copy()\n",
    "                lat_long_dict = neighborhood_dict.copy()\n",
    "                for key in neighborhood_dict.keys():\n",
    "                    value = neighborhood_dict.get(key)\n",
    "                    lat_long_dict[key] = {address_attrib: value, \"lat\" : 1.1, \"long\" : 1.1}\n",
    "                fak = \"forward?access_key=a86d264896b9d26e816f31538a0c68a8&query=\"\n",
    "                api = \"http://api.positionstack.com/v1/\"\n",
    "                for key in lat_long_dict.keys():\n",
    "                    neighborhood = lat_long_dict.get(key).get(address_attrib)\n",
    "                    lat = json.loads(requests.get(os.path.join(api,fak,neighborhood)).content)['data'][0]['latitude']\n",
    "                    long = json.loads(requests.get(os.path.join(api,fak,neighborhood)).content)['data'][0]['longitude']\n",
    "                    lat_long_dict.get(key)[\"lat\"] = lat\n",
    "                    lat_long_dict.get(key)[\"long\"] = long\n",
    "            #         print(key,lat,\"/\",long)\n",
    "                new_data[\"lat\"] = new_data[\"SalePrice\"]\n",
    "                new_data[\"long\"] = new_data[\"SalePrice\"]\n",
    "                for i in new_data.index:\n",
    "                    neighborhood = new_data[address_attrib][i]\n",
    "                    if neighborhood == \"NAmes\":\n",
    "                        neighborhood = \"Names\"\n",
    "                    lat = lat_long_dict.get(neighborhood).get(\"lat\")\n",
    "                    long = lat_long_dict.get(neighborhood).get(\"long\")\n",
    "                    new_data[\"lat\"][i] = lat\n",
    "                    new_data[\"long\"][i] = long\n",
    "            #         print (lat, long, neighborhood)\n",
    "                return new_data\n",
    "            return get_lat_long(data,'Neighborhood')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class cleaner (BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strCols, catCols, numCols, nmcCols):\n",
    "#         self.string_columns = string_columns\n",
    "#         self.cat_columns = cat_columns\n",
    "#         self.numerical_columns = numerical_columns\n",
    "#         self.numcat_columns = numcat_columns\n",
    "        self.strCols = strCols\n",
    "        self.nmcCols = nmcCols\n",
    "        self.catCols = catCols\n",
    "        self.numCols = numCols\n",
    "    def fit(self, data):\n",
    "        return self\n",
    "    def transform (self, data,y=None):\n",
    "        def remove_duplicate (data):\n",
    "#             print('remove_duplicate')\n",
    "            data_copy = data.copy()\n",
    "            data_new = data_copy.drop_duplicates()\n",
    "            return(data_new.reset_index(drop=True))\n",
    "        def decapitalizing(data,string_columns,categorical_attribs):\n",
    "#             print('decapitalizing')\n",
    "            data_copy = data.copy()\n",
    "            for column in string_columns: # decapitalizing the data\n",
    "                data_copy[column] = data_copy[column].str.lower().copy()\n",
    "\n",
    "            for col in string_columns: # decapitalizing the metadata\n",
    "                ca_copy = categorical_attribs[col].copy()\n",
    "                categorical_attribs[col] = [x.lower() for x in ca_copy]\n",
    "            return data_copy\n",
    "\n",
    "        def correct_current_typos(data,strCols):\n",
    "#             print('correct_current_typos')\n",
    "            data_copy = data.copy()\n",
    "            data_copy.replace('twnhs','twnhsi',inplace = True)\n",
    "            data_copy.replace('brk cmn','brkcomm',inplace = True)\n",
    "            data_copy.replace('cmentbd','cemntbd',inplace = True)\n",
    "            data_copy.replace('wd shng','wdshing',inplace = True)\n",
    "\n",
    "            for column in strCols:\n",
    "                data_copy[column].str.strip()\n",
    "\n",
    "            return data_copy\n",
    "\n",
    "        def strc_errors_handler(data,cat_columns, correction = True):\n",
    "#             print('strc_errors_handler')\n",
    "            data_copy = data.copy()\n",
    "\n",
    "            err_cols = {}\n",
    "            for column in cat_columns:\n",
    "                i = 0\n",
    "                while i < len(data_copy[column]):\n",
    "                    case = data_copy.at[i,column]\n",
    "                    if case not in cat_columns[column] and not pd.isna(case):\n",
    "                        print(case,cat_columns[column])\n",
    "                        if column not in err_cols.keys():\n",
    "                            err_cols[column] = set()\n",
    "                        err_cols[column].add(case)\n",
    "                        if correction:\n",
    "                            data_copy.drop(i,inplace = True)\n",
    "                    i += 1\n",
    "                data_copy = data_copy.reset_index(drop=True)\n",
    "            return data_copy.reset_index(drop=True)\n",
    "\n",
    "        def na_handler(data,numerical_columns, numcat_columns,string_columns):\n",
    "#             print('na_handler')\n",
    "            data_copy_num = data[numerical_columns].copy()\n",
    "            data_copy_numcat = data[numcat_columns].copy()\n",
    "            data_copy_string = data[string_columns].copy()\n",
    "            data_copy_selected_columns = pd.concat([data_copy_num,data_copy_numcat,data_copy_string],axis=1)\n",
    "            data_copy_remained = data_copy.drop(columns=data_copy_selected_columns)\n",
    "\n",
    "            data_copy_num.interpolate(inplace = True)\n",
    "            for col in data_copy_num:\n",
    "                i = 0\n",
    "                if (pd.isna(data_copy_num.at[0,col])):\n",
    "                    while pd.isna(data_copy_num.at[i,col]):\n",
    "                        i += 1\n",
    "                    for j in range(i):\n",
    "                        data_copy_num.at[j,col] = data_copy_num.at[j+1,col].copy()\n",
    "                data_copy_numcat.interpolate(method = 'pad', inplace = True)\n",
    "            data_copy_string.fillna(value = 'missing',inplace = True)\n",
    "            return pd.concat([data_copy_num,data_copy_numcat,data_copy_string,data_copy_remained], axis=1)\n",
    "        data_copy = data.copy()\n",
    "        m1 = remove_duplicate(data_copy).copy().reset_index(drop=True)\n",
    "        m2 = decapitalizing(m1,self.strCols,self.catCols).copy().reset_index(drop=True)\n",
    "        m3 = correct_current_typos(m2,self.strCols).copy().reset_index(drop=True)\n",
    "        m4 = na_handler(m3,self.numCols,self.nmcCols,self.strCols).copy().reset_index(drop=True)\n",
    "        m5 = strc_errors_handler(m4,self.catCols).copy().reset_index(drop=True)\n",
    "        return m5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936e0b73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_data = internal_load(\"C:/Users/h.karimi/Documents/pprojects/housing_hw/data/external/train.csv\")\n",
    "ds_spliter = create_test_case(0.2,'Id')\n",
    "train_data,test_data = ds_spliter.fit_transform(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06220137",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-9a4bb86ee561>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data[\"lat\"][i] = lat\n",
      "<ipython-input-3-9a4bb86ee561>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data[\"long\"][i] = long\n"
     ]
    }
   ],
   "source": [
    "atl = address_to_latLong()\n",
    "alted_data = atl.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586c7e22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clnr = cleaner(get_columns('str'),get_columns('cat'),get_columns('num'),get_columns('nmc'))\n",
    "cleaned_data = clnr.fit_transform(alted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb877ecc",
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class feature_scaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__  (self,numCols):\n",
    "        self.numCols = numCols\n",
    "    def fit(self,data):\n",
    "        return self\n",
    "    def transform(self,data, y=None):\n",
    "        def standardizer(data,numCols):\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            cleaned_num_data = data.copy()\n",
    "            remaining_data = pd.DataFrame()\n",
    "            for column in cleaned_num_data:\n",
    "                if column not in numCols:\n",
    "                    cleaned_num_data.drop(columns=column,inplace=True)\n",
    "                    remaining_data[column] = cleaned_data[column]\n",
    "            stndr = StandardScaler()\n",
    "            standard_cleaned_num_data = stndr.fit_transform(cleaned_num_data).copy()\n",
    "            standard_cleaned_num_data_pd = pd.DataFrame(standard_cleaned_num_data, index=cleaned_num_data.index, columns=cleaned_num_data.columns)\n",
    "            standard_cleaned_data = pd.concat([remaining_data,standard_cleaned_num_data_pd],axis=1)\n",
    "            return standard_cleaned_data\n",
    "        return standardizer(data,self.numCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec760e6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fs = feature_scaler(get_columns('num'))\n",
    "standard_cleaned_data = fs.fit_transform(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb1a678",
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class cat_data_handler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strCols, nmcCols):   \n",
    "        self.strCols = strCols\n",
    "        self.nmcCols = nmcCols\n",
    "    def fit(self, data):\n",
    "        return self\n",
    "    def transform(self,data,y=None):\n",
    "        def str_column_encoder(data, str_columns):\n",
    "            data_copy = data.copy()\n",
    "            new_data = data_copy.copy()\n",
    "            _cat_encoder = OneHotEncoder() \n",
    "            for col in str_columns:\n",
    "                new_data = new_data.drop(col, axis = 1) # isolate the non categorical data\n",
    "            for col in str_columns:\n",
    "                encoded_col = _cat_encoder.fit_transform(data_copy[col].to_numpy().reshape(-1, 1))\n",
    "                cols =[col + \": \" +str(s) for s in _cat_encoder.categories_[0]]\n",
    "                encoded_col_df = pd.DataFrame(encoded_col.toarray(), columns = cols)\n",
    "                new_data = pd.concat([new_data, encoded_col_df], axis=1)\n",
    "                encoded_col_df = pd.DataFrame({})\n",
    "            return new_data\n",
    "        return str_column_encoder(data,self.strCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d391761",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encdr = cat_data_handler(get_columns('str'),get_columns('nmc'))\n",
    "cat_handeled_data = encdr.fit_transform(standard_cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f69408",
   "metadata": {
    "code_folding": [
     20
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# class transformer_pipeLine(BaseEstimator, TransformerMixin):\n",
    "# #     def __init__(self,catCols,strCols,numCols,nmcCols,test_ratio,id_column):\n",
    "#     def __init__(self):\n",
    "#         self.catCols = get_columns('cat')\n",
    "#         self.strCols = get_columns('str')\n",
    "#         self.numCols = get_columns('num')\n",
    "#         self.nmcCols = get_columns('nmc')\n",
    "#         self.test_ratio = 2\n",
    "#         self.id_column = 'Id'\n",
    "#     def pipe_transform(self,data):\n",
    "#         from sklearn.pipeline import Pipeline\n",
    "#         from sklearn.preprocessing import StandardScaler\n",
    "#         housing_transform_pipeline = Pipeline([\n",
    "#             ('create_test_case', create_test_case(self.test_ratio,self.id_column)),\n",
    "#             ('address_to_latLong', address_to_latLong()),\n",
    "#             ('cleaner', cleaner(self.strCols, self.catCols, self.numCols, self.nmcCols)),\n",
    "#             ('feature_scaler', feature_scaler(self.numCols)),\n",
    "#             ('cat_data_handler', cat_data_handler(self.strCols,self.nmcCols))])\n",
    "#         return housing_transform_pipeline.fit_transform(data)\n",
    "    \n",
    "class transformer_pipeLine(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self,catCols,strCols,numCols,nmcCols,test_ratio,id_column):\n",
    "    def pipe_transform(self,data):\n",
    "        catCols = get_columns('cat')\n",
    "        strCols = get_columns('str')\n",
    "        numCols = get_columns('num')\n",
    "        nmcCols = get_columns('nmc')\n",
    "        test_ratio = 2\n",
    "        id_column = 'Id'\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        housing_transform_pipeline = Pipeline([\n",
    "            ('create_test_case', create_test_case(test_ratio,id_column)),\n",
    "            ('address_to_latLong', address_to_latLong()),\n",
    "            ('cleaner', cleaner(strCols,catCols, numCols, nmcCols)),\n",
    "            ('feature_scaler', feature_scaler(numCols)),\n",
    "            ('cat_data_handler', cat_data_handler(strCols,nmcCols))])\n",
    "        return housing_transform_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e9c9cb3",
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now I should make tramsformer pipline\n",
    "# put the code in right files and places\n",
    "# train a model\n",
    "# search how should I test and validate when data is manipulated. Wether done the Transform on test data and then check the result or reverse the result to original format and then check the accuracy and confidence\n",
    "# go for find out how to reverse data to original format, right for reporting to customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec5c8fcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m    350\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 351\u001B[1;33m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_range\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    352\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-23-4c813e77fe01>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# cdh = transformer_pipeLine(get_columns('cat'),get_columns('str'),get_columns('num'),get_columns('nmc'),2,'Id')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mcdh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransformer_pipeLine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mtransformed_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcdh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-13-db775e656e20>\u001B[0m in \u001B[0;36mpipe_transform\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     36\u001B[0m             \u001B[1;33m(\u001B[0m\u001B[1;34m'feature_scaler'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeature_scaler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumCols\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m             ('cat_data_handler', cat_data_handler(strCols,nmcCols))])\n\u001B[1;32m---> 38\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mhousing_transform_pipeline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    424\u001B[0m         \"\"\"\n\u001B[0;32m    425\u001B[0m         \u001B[0mfit_params_steps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_fit_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 426\u001B[1;33m         \u001B[0mXt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    427\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    428\u001B[0m         \u001B[0mlast_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_final_estimator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, y, **fit_params_steps)\u001B[0m\n\u001B[0;32m    346\u001B[0m                 \u001B[0mcloned_transformer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtransformer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m             \u001B[1;31m# Fit or load from cache the current transformer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 348\u001B[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001B[0m\u001B[0;32m    349\u001B[0m                 \u001B[0mcloned_transformer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    350\u001B[0m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    350\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    351\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 352\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    353\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcall_and_shelve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001B[0m in \u001B[0;36m_fit_transform_one\u001B[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001B[0m\n\u001B[0;32m    891\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0m_print_elapsed_time\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmessage_clsname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    892\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtransformer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"fit_transform\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 893\u001B[1;33m             \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransformer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    894\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    895\u001B[0m             \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransformer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    850\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0my\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    851\u001B[0m             \u001B[1;31m# fit method of arity 1 (unsupervised transformation)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 852\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    853\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    854\u001B[0m             \u001B[1;31m# fit method of arity 2 (supervised transformation)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-4-48b600ce1f09>\u001B[0m in \u001B[0;36mtransform\u001B[1;34m(self, data, y)\u001B[0m\n\u001B[0;32m     84\u001B[0m         \u001B[0mm2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecapitalizing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrCols\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcatCols\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m         \u001B[0mm3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcorrect_current_typos\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrCols\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m         \u001B[0mm4\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mna_handler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumCols\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnmcCols\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrCols\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m         \u001B[0mm5\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstrc_errors_handler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcatCols\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mm5\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-4-48b600ce1f09>\u001B[0m in \u001B[0;36mna_handler\u001B[1;34m(data, numerical_columns, numcat_columns, string_columns)\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mcol\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_copy_num\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m                 \u001B[0mi\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m                 \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_copy_num\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mat\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m                     \u001B[1;32mwhile\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_copy_num\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mat\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m                         \u001B[0mi\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2154\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2155\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2156\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2157\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2158\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__setitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2102\u001B[0m         \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_convert_key\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2103\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtakeable\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_takeable\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2105\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__setitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m_get_value\u001B[1;34m(self, index, col, takeable)\u001B[0m\n\u001B[0;32m   3142\u001B[0m         \u001B[1;31m# use positional\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3143\u001B[0m         \u001B[0mcol\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3144\u001B[1;33m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3145\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtakeable\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m    351\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_range\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    352\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 353\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    354\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    355\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtolerance\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "data = internal_load(\"C:/Users/h.karimi/Documents/pprojects/housing_hw/data/external/train.csv\")\n",
    "# cdh = transformer_pipeLine(get_columns('cat'),get_columns('str'),get_columns('num'),get_columns('nmc'),2,'Id')\n",
    "cdh = transformer_pipeLine()\n",
    "transformed_data = cdh.pipe_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40ed68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read the document of pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}